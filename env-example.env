# .env.example
# Przykładowy plik konfiguracji dla systemu semantycznego wyszukiwania dokumentów
# Skopiuj do .env i uzupełnij odpowiednimi wartościami

# === KONFIGURACJA BAZY DANYCH ===
DB_HOST=localhost
DB_PORT=5432
DB_NAME=semantic_docs
DB_USER=postgres
DB_PASSWORD=postgres
DB_MAX_POOL_SIZE=20
DB_MIN_POOL_SIZE=5

# === KONFIGURACJA EMBEDDINGÓW ===
# Domyślny model embeddings
DEFAULT_EMBEDDING_MODEL=all-MiniLM-L6-v2

# Klucz API OpenAI (opcjonalny - dla modeli OpenAI)
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_ORG_ID=org-your-org-id-here

# Hugging Face token (opcjonalny - dla prywatnych modeli)
HF_TOKEN=your-huggingface-token-here

# === KONFIGURACJA WYSZUKIWANIA ===
# Domyślna waga dla wyszukiwania hybrydowego (0.0-1.0)
DEFAULT_SEMANTIC_WEIGHT=0.7

# Minimalne score dla wyników wyszukiwania
DEFAULT_MIN_SCORE=0.3

# Maksymalna liczba wyników
DEFAULT_LIMIT=10

# === KONFIGURACJA PRZETWARZANIA TEKSTU ===
# Rozmiar chunków dla długich dokumentów
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Język dla przetwarzania tekstu
DEFAULT_LANGUAGE=polish

# === KONFIGURACJA INDEKSÓW WEKTOROWYCH ===
# Liczba list dla indeksu IVFFlat
IVFFLAT_LISTS=100

# Parametry dla indeksu HNSW
HNSW_M=16
HNSW_EF_CONSTRUCTION=64

# === KONFIGURACJA CACHE ===
# Redis (opcjonalny)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

# Cache dla embeddingów
ENABLE_EMBEDDING_CACHE=true
CACHE_TTL_SECONDS=3600

# === KONFIGURACJA LOGOWANIA ===
LOG_LEVEL=INFO
LOG_FORMAT=json
LOG_FILE=/app/logs/semantic-docs.log

# Czy logować zapytania SQL
LOG_SQL_QUERIES=false

# === KONFIGURACJA WYDAJNOŚCI ===
# Maksymalna liczba wątków dla przetwarzania batch
MAX_WORKERS=4

# Timeout dla operacji AI w sekundach
AI_TIMEOUT_SECONDS=30

# Batch size dla przetwarzania embeddingów
EMBEDDING_BATCH_SIZE=32

# === KONFIGURACJA BEZPIECZEŃSTWA ===
# Klucz szyfrowania dla sesji (wygeneruj losowy)
SECRET_KEY=your-super-secret-key-change-this-in-production

# Czy wymagać HTTPS
REQUIRE_HTTPS=false

# CORS origins (dla API)
CORS_ORIGINS=http://localhost:3000,http://localhost:8080

# === KONFIGURACJA ŚRODOWISKA ===
# Środowisko: development, staging, production
ENVIRONMENT=development

# Czy włączyć tryb debug
DEBUG=true

# Czy ładować przykładowe dane przy inicjalizacji
LOAD_SAMPLE_DATA=false

# === KONFIGURACJA DOCKER ===
# Port dla aplikacji (jeśli używasz serwera)
APP_PORT=8000

# pgAdmin credentials (dla Docker Compose)
PGADMIN_EMAIL=admin@example.com
PGADMIN_PASSWORD=admin

# === KONFIGURACJA MONITORINGU ===
# Prometeus metrics endpoint
ENABLE_METRICS=false
METRICS_PORT=9090

# Health check endpoint
ENABLE_HEALTH_CHECK=true

# === KONFIGURACJA JUPYTER (dla Docker Compose) ===
# Token dla Jupyter Notebook
JUPYTER_TOKEN=semantic

# === KONFIGURACJA AI PROVIDERS ===
# Anthropic Claude (przyszłe wsparcie)
ANTHROPIC_API_KEY=your-anthropic-key-here

# Cohere embeddings (przyszłe wsparcie)
COHERE_API_KEY=your-cohere-key-here

# === ZAAWANSOWANE USTAWIENIA ===
# Czy używać kompresji dla embeddingów
USE_VECTOR_COMPRESSION=false

# Precyzja dla obliczeń wektorowych
VECTOR_PRECISION=float32

# Czy włączyć automatyczne backup embeddingów
AUTO_BACKUP_EMBEDDINGS=false

# Ścieżka do backupów
BACKUP_PATH=/app/backups

# === USTAWIENIA DEVELOPERSKIE ===
# Czy przeładowywać automatycznie przy zmianach kodu
AUTO_RELOAD=true

# Czy wyświetlać szczegółowe informacje o błędach
SHOW_ERROR_DETAILS=true

# Profiling wydajności
ENABLE_PROFILING=false